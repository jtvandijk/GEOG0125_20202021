<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science</title>
  <meta name="description" content="2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://jtvandijk.github.io/GEOG0125/" />
  
  <meta property="og:description" content="2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science." />
  <meta name="github-repo" content="jtvandijk/GEOG0125" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science" />
  
  <meta name="twitter:description" content="2 Statistical Inference and Causality | GEOG0125: Advanced Topics in Social and Geographic Data Science." />
  

<meta name="author" content="Justin van Dijk and Stephen Law" />


<meta name="date" content="2021-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="introduction-to-deep-learning.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="libs/vembedr-0.1.4/css/vembedr.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="assets/custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo">
<a href="https://www.ucl.ac.uk/module-catalogue/modules/advanced-topics-in-social-data-science-GEOG0125"><img src="images/general/ucl_logo.png">
</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#weekly-topics"><i class="fa fa-check"></i>Weekly topics</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#moodle"><i class="fa fa-check"></i>Moodle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#useful-additional-resources"><i class="fa fa-check"></i>Useful additional resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#office-hours"><i class="fa fa-check"></i>Office hours</a></li>
</ul></li>
<li class="part"><span><b>Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="part"><span><b>Inference</b></span></li>
<li class="chapter" data-level="2" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html"><i class="fa fa-check"></i><b>2</b> Statistical Inference and Causality</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#intro-w09"><i class="fa fa-check"></i><b>2.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#reading-list-w01"><i class="fa fa-check"></i><b>2.1.1</b> Reading list</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#technical-help-session"><i class="fa fa-check"></i><b>2.1.2</b> Technical Help session</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#statistical-inference"><i class="fa fa-check"></i><b>2.2</b> Statistical inference</a></li>
<li class="chapter" data-level="2.3" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#causality"><i class="fa fa-check"></i><b>2.3</b> Causality</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#what-is-causality"><i class="fa fa-check"></i><b>2.3.1</b> What is causality?</a></li>
<li class="chapter" data-level="2.3.2" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#the-problem-with-causality"><i class="fa fa-check"></i><b>2.3.2</b> The problem with causality</a></li>
<li class="chapter" data-level="2.3.3" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#fixed-effects-models"><i class="fa fa-check"></i><b>2.3.3</b> Fixed effects models</a></li>
<li class="chapter" data-level="2.3.4" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#random-effects-models"><i class="fa fa-check"></i><b>2.3.4</b> Random effects models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#thm-w02"><i class="fa fa-check"></i><b>2.4</b> Take home message</a></li>
<li class="chapter" data-level="2.5" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#attributions_w02"><i class="fa fa-check"></i><b>2.5</b> Attributions</a></li>
</ul></li>
<li class="part"><span><b>GeoAI</b></span></li>
<li class="chapter" data-level="3" data-path="introduction-to-deep-learning.html"><a href="introduction-to-deep-learning.html"><i class="fa fa-check"></i><b>3</b> Introduction to Deep Learning</a></li>
<li class="chapter" data-level="4" data-path="keynote-spatial-data-science.html"><a href="keynote-spatial-data-science.html"><i class="fa fa-check"></i><b>4</b> Keynote: Spatial Data Science</a></li>
<li class="chapter" data-level="5" data-path="convolutional-neural-networks.html"><a href="convolutional-neural-networks.html"><i class="fa fa-check"></i><b>5</b> Convolutional Neural Networks</a></li>
<li class="chapter" data-level="6" data-path="spatial-data-science-applications.html"><a href="spatial-data-science-applications.html"><i class="fa fa-check"></i><b>6</b> Spatial Data Science Applications</a></li>
<li class="chapter" data-level="7" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html"><i class="fa fa-check"></i><b>7</b> Spatial-Temporal Mobility Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#intro-w07"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#reading-list-w07"><i class="fa fa-check"></i><b>7.1.1</b> Reading list</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistical-inference-and-causality.html"><a href="statistical-inference-and-causality.html#technical-help-session"><i class="fa fa-check"></i><b>7.1.2</b> Technical Help session</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#gps-data"><i class="fa fa-check"></i><b>7.2</b> GPS data</a></li>
<li class="chapter" data-level="7.3" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#gps-data-classification"><i class="fa fa-check"></i><b>7.3</b> GPS data classification</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#gps-data-preparation"><i class="fa fa-check"></i><b>7.3.1</b> GPS data preparation</a></li>
<li class="chapter" data-level="7.3.2" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#gps-data-classification-1"><i class="fa fa-check"></i><b>7.3.2</b> GPS data classification</a></li>
<li class="chapter" data-level="7.3.3" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#exercise"><i class="fa fa-check"></i><b>7.3.3</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#take-home-message"><i class="fa fa-check"></i><b>7.4</b> Take home message</a></li>
<li class="chapter" data-level="7.5" data-path="spatial-temporal-mobility-analysis.html"><a href="spatial-temporal-mobility-analysis.html#attributions_w07"><i class="fa fa-check"></i><b>7.5</b> Attributions</a></li>
</ul></li>
<li class="part"><span><b>Data Sciencist’s Toolbox</b></span></li>
<li class="chapter" data-level="8" data-path="unix-tools.html"><a href="unix-tools.html"><i class="fa fa-check"></i><b>8</b> Unix tools</a></li>
<li class="chapter" data-level="9" data-path="web-visualisation.html"><a href="web-visualisation.html"><i class="fa fa-check"></i><b>9</b> Web Visualisation</a></li>
<li class="part"><span><b>Future</b></span></li>
<li class="chapter" data-level="10" data-path="a-look-into-the-future.html"><a href="a-look-into-the-future.html"><i class="fa fa-check"></i><b>10</b> A look into the future</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GEOG0125: Advanced Topics in Social and Geographic Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-inference-and-causality" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Statistical Inference and Causality</h1>
<div id="intro-w09" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Introduction</h2>
<p>Statistical inference is the process of using data analysis to deduce properties of an underlying distribution of probability. In other words: statistical inference is the procedure through which we try to make inferences about a population based on characteristics of this population that have been captured in a sample. This includes uncovering the association between variables as well as establishing causal relationships. However, correlation does not imply causation and identifying causal relationships from observational data is not trivial.</p>
<blockquote>
<p>“Correlation does not imply causation” (Any statistician).</p>
</blockquote>
<p>This week we will dive a little deeper into statistical inference and how to establish causal relationships by taking a small dive into the field of study of <a href="https://en.wikipedia.org/wiki/Econometrics#:~:text=Econometrics%20is%20the%20application%20of,by%20appropriate%20methods%20of%20inference%22.">econometrics</a>.</p>
<p>This week’s lecture video is provided by an absolute expert in the field of econometrics: <a href="https://www.uj.ac.za/contact/Pages/Love-Idahosa.aspx">Dr Idahosa</a> from the <a href="https://www.uj.ac.za/">University of Johannesburg</a>. This week is further structured by reading material, a tutorial in R with a ‘hands-on’ application of the techniques covered in the lecture video, and a seminar on Tuesday.</p>
<p>Let’s get to it!</p>
<div id="video-introduction-w01" class="section level4 unnumbered">
<h4>Video: Introduction W01</h4>
<p><div class="vembedr" align="left">
<div>
<iframe src="https://web.microsoftstream.com/embed/video/b2d5835e-7137-4c9e-aa9c-9101d62b9e94?autoplay=false&amp;showinfo=true" width="533" height="300" style="border:none;"></iframe>
</div>
</div>
[Lecture slides] <a href="https://web.microsoftstream.com/video/b2d5835e-7137-4c9e-aa9c-9101d62b9e94">[Watch on MS stream]</a></p>
</div>
<div id="reading-list-w01" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Reading list</h3>
<p>Please find the reading list for this week below.</p>
<div id="core-reading" class="section level4 unnumbered">
<h4>Core reading</h4>
<ul>
<li>Bzdok, D., Altman, and M. Krzywinski. 2018. Statistics versus machine learning. <em>Nature Methods</em> 15: 233-234. <a href="https://www.nature.com/articles/nmeth.4642">[Link]</a></li>
<li>Idahosa, L. O., Marwa, N., and J. Akotey. 2017. Energy (electricity) consumption in South African hotels: A panel data analysis. <em>Energy and Buildings</em> 156: 207-217. <a href="https://ucl-new-primo.hosted.exlibrisgroup.com/permalink/f/1klfcc3/TN_cdi_gale_infotracacademiconefile_A523007644">[Link]</a></li>
<li>Stock, J. and M. Watson. 2019. <strong>Chapter 1</strong>: <em>Economic Questions and Data</em>. In: Stock, J. and M. Watson. Introduction to Econometrics, pp.43-54. Harlow: Pearson Education Ltd. <a href="https://ucl-new-primo.hosted.exlibrisgroup.com/permalink/f/1klfcc3/TN_cdi_proquest_ebookcentral_EBC6399072">[Link]</a></li>
<li>Stock, J. and M. Watson. 2019. <strong>Chapter 10</strong>: <em>Regression with Panel Data</em>. In: Stock, J. and M. Watson. Introduction to Econometrics, pp.362-382. Harlow: Pearson Education Ltd. <a href="https://ucl-new-primo.hosted.exlibrisgroup.com/permalink/f/1klfcc3/TN_cdi_proquest_ebookcentral_EBC6399072">[Link]</a></li>
</ul>
</div>
<div id="supplementary-reading" class="section level4 unnumbered">
<h4>Supplementary reading</h4>
<ul>
<li>Idahosa, L. O. and J. T. van Dijk. 2016. South Africa: Freedom for whom? Inequality, unemployment and the elderly. <em>Development</em> 58(1): 96-102. <a href="https://ucl-new-primo.hosted.exlibrisgroup.com/permalink/f/1klfcc3/TN_cdi_proquest_journals_1758956430">[Link]</a></li>
</ul>
</div>
</div>
<div id="technical-help-session" class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Technical Help session</h3>
<p>Every Thursday between 13h00-14h00 you can join the <strong>Technical Help</strong> session on Microsoft Teams. The session will be hosted by <a href="https://www.ucl.ac.uk/geospatial-analytics/people/alfie-long">Alfie</a>. He will be there for the whole hour to answer any question you have live in the meeting or any questions you have formulated beforehand. If you cannot make the meeting, feel free to post the issue you are having in the Technical Help channel on the GEOG0125 Team so that Alfie can help to find a solution.</p>
</div>
</div>
<div id="statistical-inference" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Statistical inference</h2>
<p>Where during the remainder of this module we will predominantly focus on different <a href="https://en.wikipedia.org/wiki/Machine_learning#:~:text=Machine%20learning%20(ML)%20is%20the,a%20subset%20of%20artificial%20intelligence.">machine learning</a> methods and techniques and the data scientist’s toolbox, this week we will focus on statistical inference. Although there is considerable overlap between machine learning and statistics, sometimes even involving the same methods, the major difference between machine learning and statistics is their purpose. Where machine learning models are designed to make <em>accurate predictions</em>, statistical models are designed for inference about the <em>relationships between variables</em>.</p>
<blockquote>
<p>“Statistics draws population inferences from a sample, and machine learning finds generalizable
predictive patterns” (Bzdok <em>et al.</em> 2018).</p>
</blockquote>
<p>One way to analyse the relationships between variables is by a linear regression. Linear regression models offer a very <strong>interpretable</strong> way to model the association between variables. A linear regression model is used to find the line that minimises the mean squared error across all data to establish the relationship between a response variable one or more explanatory (independent) variables. The case of one explanatory variable is called a simple linear regression; if more explanatory variables are used it is called multiple regression. The purpose of a regression model is to predict a target variable <span class="math inline">\(Y\)</span> according to some other variable <span class="math inline">\(X\)</span> or variables <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, etc.</p>
</div>
<div id="causality" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Causality</h2>
<div id="what-is-causality" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> What is causality?</h3>
<p>Regression cares about correlation: what happens to <span class="math inline">\(Y\)</span> when <span class="math inline">\(X=x\)</span>. However, correlation does not imply causation. A great example can be found in a research project reporting on the relationships between <a href="https://www.reuters.com/article/us-eat-chocolate-win-the-nobel-prize/eat-chocolate-win-the-nobel-prize-idUSBRE8991MS20121010">chocolate consumption and the probability of winning a Nobel price</a>. The results suggest that countries in which the population consumes on average a large amount of chocolate per annum, spawn more Nobel laureates per capita than countries in which the population on average consume less chocolate. There is a clear correlation in the data, but there should not exist an actual causal relationship between these two variables (Well, some <a href="https://doi.org/10.1016/j.ssaho.2020.100082">research suggests it still remains unclear</a> whether the correlation is spurious or whether it is an indication for hidden variables …)</p>
<p>The golden standard to establish a causal relationship is to set-up and execute <a href="https://adc.bmj.com/content/90/8/840">a randomised control trial</a>. Think of the many large-scale randomised control trials that are currently taking place to test the safety and effectiveness of various candidate coronavirus vaccines. However, it is not always possible to set up a randomised control trial. Sometimes this has to do with the nature of the relationship being investigated (e.g. establishing the effects of policy changes), but there could also be financial and ethical constraints. As an alternative, one could try to identify causal relationship from observational data. This is known as causal inference and most research in econometrics is concerned with retrieving valid estimates using different regression methods.</p>
<div class="note">
<p><strong>Note</strong><br/>
The distinction between causal and non-causal relationships is crucial and heavily depends on your research questions. If you are trying to classify Google Street view images and predict whether the photo contains an office building or a residential building, you want to create a model that predicts this as good as possible. However, you do not care about what caused the building in the photo to be an office building or a residential building. That being said: almost any question is causal and where statistics is used in almost any field of inquiry, few pay proper attention to understanding causality.</p>
</div>
<p>By now you may wonder, sure, but what then is causality? We can say that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> if we were to change the value of <span class="math inline">\(X\)</span> without changing anything else then as a result <span class="math inline">\(Y\)</span> would also change. A simple example: if you switch on the light switch, your light bulb will go on. The action of flipping the light switch <strong>causes</strong> your light to go on. This being said: it does not mean that <span class="math inline">\(X\)</span> is necessarily the only thing that causes <span class="math inline">\(Y\)</span> (e.g. the light bulb is burnt out or the light was already on) and perhaps a better way of phrasing it is to say that there is a <strong>causal relationship</strong> between variables if <span class="math inline">\(X\)</span> changes the probability of <span class="math inline">\(Y\)</span> happening or changing.</p>
</div>
<div id="the-problem-with-causality" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> The problem with causality</h3>
<p>The problem with establishing a causal relationship is that in many cases you cannot ‘switch on’ or ‘switch off’ a characteristic. Let’s go through this by thinking whether some <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>. Our <span class="math inline">\(X\)</span> is coded as 0 or 1, for instance, 0 if a person has not received a coronavirus vaccination and 1 if a person has received a coronavirus vaccination. <span class="math inline">\(Y\)</span> is some numeric value. So how do we check if <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>? What we would need to do for everyone in our sample is to check what happens to <span class="math inline">\(Y\)</span> when we make <span class="math inline">\(X=0\)</span> and what happens to <span class="math inline">\(Y\)</span> when we make <span class="math inline">\(X=1\)</span>. Obviously, this is a problem! You cannot both have <span class="math inline">\(X=0\)</span> and <span class="math inline">\(X=1\)</span>: you either got inoculated against the coronavirus or you did not. This means that if <span class="math inline">\(X=1\)</span> you can measure what the value of <span class="math inline">\(Y\)</span> is, but you do not know what the value of <span class="math inline">\(Y\)</span> <strong>would have been</strong> if <span class="math inline">\(X=0\)</span>. The solution you may come up with is to compare <span class="math inline">\(Y\)</span> between individuals who have <span class="math inline">\(X=0\)</span> and <span class="math inline">\(X=1\)</span>. However, there is another problem: there could be all kinds of reasons on why <span class="math inline">\(Y\)</span> differs between individuals that are not necessarily related to <span class="math inline">\(X\)</span>.</p>
<div class="note">
<p><strong>Note</strong><br/>
This section heavily borrows material and explanations from Nick Huntington-Klein’s excellent <a href="http://www.nickchk.com/econ305.html">ECON 305: Economics, Causality, and Analytics</a> module, do have a look if you want to learn more about this topic.</p>
</div>
<p>This brings us to econometrics and causal inference: the main goal of causal inference is to make the best possible estimation of what <span class="math inline">\(Y\)</span> would have been if <span class="math inline">\(X\)</span> would have been different, the so-called <strong>counterfactual</strong>. As we cannot always use an experiment in which we can randomly assign <span class="math inline">\(X\)</span> so that we know that on average people with <span class="math inline">\(X=1\)</span> and the same as people with <span class="math inline">\(X=2\)</span>, we have to come up with a model to figure out what the counterfactual would do.</p>
<p>In the following, we will explore two ways of doing this through so-called fixed effects models and random effects models in the situation in which we have data points for each observation across time (i.e. <a href="https://en.wikipedia.org/wiki/Longitudinal_study">longitudinal data</a> or <a href="https://en.wikipedia.org/wiki/Panel_data">panel data</a>).</p>
<div id="video-panel-data-analysis" class="section level4 unnumbered">
<h4>Video: Panel Data Analysis</h4>
<p><div class="vembedr" align="left">
<div>
<iframe src="https://web.microsoftstream.com/embed/video/a533a384-4acd-4583-90af-348a1c3d3388?autoplay=false&amp;showinfo=true" width="533" height="300" style="border:none;"></iframe>
</div>
</div>
<a href="https://github.com/jtvandijk/GEOG0125/blob/master/slides/w02/w02_introduction_panel_data.pdf">[Lecture slides]</a> <a href="https://web.microsoftstream.com/video/a533a384-4acd-4583-90af-348a1c3d3388">[Watch on MS stream]</a></p>
</div>
</div>
<div id="fixed-effects-models" class="section level3" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Fixed effects models</h3>
<p>Fixed effects are variables that are constant across individuals; these variables, like age, sex, or ethnicity, typically do not change over time or change over time at a constant rate. As such, they have fixed effects on a dependent variable <span class="math inline">\(Y\)</span>. As such, using a fixed effects model you can explore the relationship between variables within an entity (which could be persons, companies, countries, etc.). Each entity has its own individual characteristics that may or may not influence the dependent variable. When using a fixed effects model, we assume that something within the entity may impact or bias the dependent variables and we need to control for this. A fixed effects model does this by removing the characteristics that do not change over time so that we can assess the net effect of the independent variables on the dependent variable.</p>
<p>Let’s try to to apply a fixed effects model in R. For this we will use a data set containing some <a href="https://en.wikipedia.org/wiki/Panel_data">panel data</a>. The data set contains fictional data, for different countries and years, for an undefined variable <span class="math inline">\(Y\)</span> that we want to explain with some other variables.</p>
<div id="file-download" class="section level4 unnumbered">
<h4>File download</h4>
<table>
<thead>
<tr class="header">
<th align="left">File</th>
<th align="left">Type</th>
<th align="left">Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Example Panel Data</td>
<td align="left"><code>csv</code></td>
<td align="left"><a href="https://github.com/jtvandijk/GEOG0125/tree/master/raw/zip/paneldata.zip">Download</a></td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="statistical-inference-and-causality.html#cb1-1" aria-hidden="true"></a><span class="co"># load libraries</span></span>
<span id="cb1-2"><a href="statistical-inference-and-causality.html#cb1-2" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="statistical-inference-and-causality.html#cb1-3" aria-hidden="true"></a><span class="kw">library</span>(plm)</span>
<span id="cb1-4"><a href="statistical-inference-and-causality.html#cb1-4" aria-hidden="true"></a><span class="kw">library</span>(car)</span>
<span id="cb1-5"><a href="statistical-inference-and-causality.html#cb1-5" aria-hidden="true"></a><span class="kw">library</span>(gplots)</span>
<span id="cb1-6"><a href="statistical-inference-and-causality.html#cb1-6" aria-hidden="true"></a><span class="kw">library</span>(tseries)</span>
<span id="cb1-7"><a href="statistical-inference-and-causality.html#cb1-7" aria-hidden="true"></a><span class="kw">library</span>(lmtest)</span>
<span id="cb1-8"><a href="statistical-inference-and-causality.html#cb1-8" aria-hidden="true"></a></span>
<span id="cb1-9"><a href="statistical-inference-and-causality.html#cb1-9" aria-hidden="true"></a><span class="co"># read data</span></span>
<span id="cb1-10"><a href="statistical-inference-and-causality.html#cb1-10" aria-hidden="true"></a>country_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&#39;raw/w02/paneldata.csv&#39;</span>)</span>
<span id="cb1-11"><a href="statistical-inference-and-causality.html#cb1-11" aria-hidden="true"></a></span>
<span id="cb1-12"><a href="statistical-inference-and-causality.html#cb1-12" aria-hidden="true"></a><span class="co"># inspect</span></span>
<span id="cb1-13"><a href="statistical-inference-and-causality.html#cb1-13" aria-hidden="true"></a><span class="kw">head</span>(country_data)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   country  year           y    x1     x2      x3
##   &lt;chr&gt;   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 A        1990  1342787840 0.278 -1.11   0.283 
## 2 A        1991 -1899660544 0.321 -0.949  0.493 
## 3 A        1992   -11234363 0.363 -0.789  0.703 
## 4 A        1993  2645775360 0.246 -0.886 -0.0944
## 5 A        1994  3008334848 0.425 -0.730  0.946 
## 6 A        1995  3229574144 0.477 -0.723  1.03</code></pre>
<p>Upon inspecting the <code>dataframe</code> you can see that the data contains 8 different fictional countries. For each country we have several years of data: three independent variables names <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, and <span class="math inline">\(X_{3}\)</span> and a dependent variable <span class="math inline">\(y\)</span>. As this is a panel dataset we have to declare it as such using the <code>plm.data()</code> function from the <code>plm</code> package. The <code>plm</code> package is a library dedicated to panel data analysis.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="statistical-inference-and-causality.html#cb3-1" aria-hidden="true"></a><span class="co"># create a panel data object</span></span>
<span id="cb3-2"><a href="statistical-inference-and-causality.html#cb3-2" aria-hidden="true"></a>country_panel &lt;-<span class="st"> </span><span class="kw">pdata.frame</span>(country_data, <span class="dt">index=</span><span class="kw">c</span>(<span class="st">&#39;country&#39;</span>,<span class="st">&#39;year&#39;</span>))</span>
<span id="cb3-3"><a href="statistical-inference-and-causality.html#cb3-3" aria-hidden="true"></a></span>
<span id="cb3-4"><a href="statistical-inference-and-causality.html#cb3-4" aria-hidden="true"></a><span class="co"># inspect</span></span>
<span id="cb3-5"><a href="statistical-inference-and-causality.html#cb3-5" aria-hidden="true"></a>country_panel</span></code></pre></div>
<pre><code>##        country year           y        x1         x2          x3
## A-1990       A 1990  1342787840 0.2779037 -1.1079559  0.28255358
## A-1991       A 1991 -1899660544 0.3206847 -0.9487200  0.49253848
## A-1992       A 1992   -11234363 0.3634657 -0.7894840  0.70252335
## A-1993       A 1993  2645775360 0.2461440 -0.8855330 -0.09439092
## A-1994       A 1994  3008334848 0.4246230 -0.7297683  0.94613063
##  [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 65 rows ]</code></pre>
<p>Although the data looks the same, you can see that the row index has been updated to reflect the <code>country</code> and <code>year</code> variables. Let’s inspect the data using a boxplot as well as a <a href="https://www.oreilly.com/library/view/graphing-data-with/9781491922606/ch18.html">conditioning plot</a>. A coplot is a method for visualising interactions in your data set: it shows you how some variables are conditional on some other set of variables. So, for our panel data set, we can look at the variation of <span class="math inline">\(Y\)</span> over time by country. The bars at top indicate the countries position from left to right starting on the bottom row.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="statistical-inference-and-causality.html#cb5-1" aria-hidden="true"></a><span class="co"># create a quick box plot</span></span>
<span id="cb5-2"><a href="statistical-inference-and-causality.html#cb5-2" aria-hidden="true"></a><span class="kw">scatterplot</span>(y <span class="op">~</span><span class="st"> </span>year, <span class="dt">data=</span>country_panel)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-co-plot-1.png" width="672" /></p>
<pre><code>## [1] &quot;11&quot; &quot;54&quot; &quot;45&quot; &quot;55&quot; &quot;46&quot; &quot;36&quot; &quot;59&quot;</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="statistical-inference-and-causality.html#cb7-1" aria-hidden="true"></a><span class="co"># create a quick conditioning plot</span></span>
<span id="cb7-2"><a href="statistical-inference-and-causality.html#cb7-2" aria-hidden="true"></a><span class="kw">coplot</span>(y <span class="op">~</span><span class="st"> </span>year<span class="op">|</span>country, <span class="dt">data=</span>country_panel, <span class="dt">type=</span><span class="st">&#39;b&#39;</span>)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-co-plot-2.png" width="672" /></p>
<p>The graphs show that there <span class="math inline">\(Y\)</span> is variable both over time and between countries. Let’s also have a look at the <a href="https://en.wikipedia.org/wiki/Homogeneity_and_heterogeneity">heterogeneity</a> of our data by plotting the means, and the 95% confidence interval around the means, of <span class="math inline">\(Y\)</span> across time and across countries.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="statistical-inference-and-causality.html#cb8-1" aria-hidden="true"></a><span class="co"># means across years</span></span>
<span id="cb8-2"><a href="statistical-inference-and-causality.html#cb8-2" aria-hidden="true"></a><span class="kw">plotmeans</span>(y <span class="op">~</span><span class="st"> </span>year, <span class="dt">data=</span>country_panel)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-heterogeneity-1.png" width="672" /></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="statistical-inference-and-causality.html#cb9-1" aria-hidden="true"></a><span class="co"># means across countries</span></span>
<span id="cb9-2"><a href="statistical-inference-and-causality.html#cb9-2" aria-hidden="true"></a><span class="kw">plotmeans</span>(y <span class="op">~</span><span class="st"> </span>country, <span class="dt">data=</span>country_panel)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-heterogeneity-2.png" width="672" /></p>
<p>There is clearly some heterogeneity across the countries and across years. However, the basic Ordinary Least Squares (OLS) regression model does not consider this heterogeneity:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="statistical-inference-and-causality.html#cb10-1" aria-hidden="true"></a><span class="co"># run an OLS</span></span>
<span id="cb10-2"><a href="statistical-inference-and-causality.html#cb10-2" aria-hidden="true"></a>ols &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data=</span>country_panel)</span>
<span id="cb10-3"><a href="statistical-inference-and-causality.html#cb10-3" aria-hidden="true"></a></span>
<span id="cb10-4"><a href="statistical-inference-and-causality.html#cb10-4" aria-hidden="true"></a><span class="co"># summary</span></span>
<span id="cb10-5"><a href="statistical-inference-and-causality.html#cb10-5" aria-hidden="true"></a><span class="kw">summary</span>(ols)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1, data = country_panel)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -9.546e+09 -1.578e+09  1.554e+08  1.422e+09  7.183e+09 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 1.524e+09  6.211e+08   2.454   0.0167 *
## x1          4.950e+08  7.789e+08   0.636   0.5272  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.028e+09 on 68 degrees of freedom
## Multiple R-squared:  0.005905,	Adjusted R-squared:  -0.008714 
## F-statistic: 0.4039 on 1 and 68 DF,  p-value: 0.5272</code></pre>
<p>The results show that there is no significant statistical relationship between <span class="math inline">\(X_{1}\)</span> and the dependent variable <span class="math inline">\(Y\)</span> as the model tries to explain all variability in the data at once. You can clearly see this in the plot below:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="statistical-inference-and-causality.html#cb12-1" aria-hidden="true"></a><span class="co"># plot the results</span></span>
<span id="cb12-2"><a href="statistical-inference-and-causality.html#cb12-2" aria-hidden="true"></a><span class="kw">scatterplot</span>(country_panel<span class="op">$</span>y <span class="op">~</span><span class="st"> </span>country_panel<span class="op">$</span>x1, <span class="dt">boxplots=</span><span class="ot">FALSE</span>, <span class="dt">smooth=</span><span class="ot">FALSE</span>, <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb12-3"><a href="statistical-inference-and-causality.html#cb12-3" aria-hidden="true"></a></span>
<span id="cb12-4"><a href="statistical-inference-and-causality.html#cb12-4" aria-hidden="true"></a><span class="co"># add the OLS regression line</span></span>
<span id="cb12-5"><a href="statistical-inference-and-causality.html#cb12-5" aria-hidden="true"></a><span class="kw">abline</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data=</span>country_panel),<span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-plot-the-ols-1.png" width="672" /></p>
<p>One way of getting around this, and fixing the effects of the <em>country</em> variable, is by using a model incorporating dummy variables through a Least Squares Dummy Variable model (LSDV).</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="statistical-inference-and-causality.html#cb13-1" aria-hidden="true"></a><span class="co"># run a LSDV</span></span>
<span id="cb13-2"><a href="statistical-inference-and-causality.html#cb13-2" aria-hidden="true"></a>fixed_dum &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(country) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>country_panel)</span>
<span id="cb13-3"><a href="statistical-inference-and-causality.html#cb13-3" aria-hidden="true"></a></span>
<span id="cb13-4"><a href="statistical-inference-and-causality.html#cb13-4" aria-hidden="true"></a><span class="co"># summary</span></span>
<span id="cb13-5"><a href="statistical-inference-and-causality.html#cb13-5" aria-hidden="true"></a><span class="kw">summary</span>(fixed_dum)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + factor(country) - 1, data = country_panel)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -8.634e+09 -9.697e+08  5.405e+08  1.386e+09  5.612e+09 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## x1                2.476e+09  1.107e+09   2.237  0.02889 *  
## factor(country)A  8.805e+08  9.618e+08   0.916  0.36347    
## factor(country)B -1.058e+09  1.051e+09  -1.006  0.31811    
## factor(country)C -1.723e+09  1.632e+09  -1.056  0.29508    
## factor(country)D  3.163e+09  9.095e+08   3.478  0.00093 ***
## factor(country)E -6.026e+08  1.064e+09  -0.566  0.57329    
##  [ reached getOption(&quot;max.print&quot;) -- omitted 2 rows ]
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.796e+09 on 62 degrees of freedom
## Multiple R-squared:  0.4402,	Adjusted R-squared:  0.368 
## F-statistic: 6.095 on 8 and 62 DF,  p-value: 8.892e-06</code></pre>
<p>The least square dummy variable model (LSDV) provides a good way to understand fixed effects. By adding the dummy for each country, we are now estimating the pure effect of <span class="math inline">\(X_{1}\)</span> on <span class="math inline">\(Y\)</span>. Each dummy is absorbing the effects that are particular to each country. Where the independent variable <span class="math inline">\(X_{1}\)</span> was not significant in the OLS model, after controlling for differences across countries, <span class="math inline">\(X_{1}\)</span> became significant in the LSDV model. You can clearly see why this is happening in the plot below:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="statistical-inference-and-causality.html#cb15-1" aria-hidden="true"></a><span class="co"># plot the results</span></span>
<span id="cb15-2"><a href="statistical-inference-and-causality.html#cb15-2" aria-hidden="true"></a><span class="kw">scatterplot</span>(fixed_dum<span class="op">$</span>fitted <span class="op">~</span><span class="st"> </span>country_panel<span class="op">$</span>x1<span class="op">|</span>country_panel<span class="op">$</span>country, <span class="dt">boxplots=</span><span class="ot">FALSE</span>, <span class="dt">smooth=</span><span class="ot">FALSE</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>)</span></code></pre></div>
<pre><code>## Warning in scatterplot.default(X[, 2], X[, 1], groups = X[, 3], xlab = xlab, : number of groups exceeds number of available colors
##   colors are recycled</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="statistical-inference-and-causality.html#cb17-1" aria-hidden="true"></a><span class="co"># add the LSDV regression lines</span></span>
<span id="cb17-2"><a href="statistical-inference-and-causality.html#cb17-2" aria-hidden="true"></a><span class="kw">abline</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data=</span>country_panel),<span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</span></code></pre></div>
<p><img src="GEOG0125_files/figure-html/02-plot-the-lsdv-1.png" width="672" /></p>
<p>We can also run a country-specific fixed effects model by using specific intercepts for each country. We can achieve this by using the <code>plm</code> package.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="statistical-inference-and-causality.html#cb18-1" aria-hidden="true"></a><span class="co"># run a fixed effects model</span></span>
<span id="cb18-2"><a href="statistical-inference-and-causality.html#cb18-2" aria-hidden="true"></a>fixed_effects &lt;-<span class="st"> </span><span class="kw">plm</span>(y <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data=</span>country_panel, <span class="dt">model=</span><span class="st">&#39;within&#39;</span>)</span>
<span id="cb18-3"><a href="statistical-inference-and-causality.html#cb18-3" aria-hidden="true"></a></span>
<span id="cb18-4"><a href="statistical-inference-and-causality.html#cb18-4" aria-hidden="true"></a><span class="co"># summary</span></span>
<span id="cb18-5"><a href="statistical-inference-and-causality.html#cb18-5" aria-hidden="true"></a><span class="kw">summary</span>(fixed_effects)</span></code></pre></div>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = y ~ x1, data = country_panel, model = &quot;within&quot;)
## 
## Balanced Panel: n = 7, T = 10, N = 70
## 
## Residuals:
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## -8.63e+09 -9.70e+08  5.40e+08  0.00e+00  1.39e+09  5.61e+09 
## 
## Coefficients:
##      Estimate Std. Error t-value Pr(&gt;|t|)  
## x1 2475617742 1106675596   2.237  0.02889 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    5.2364e+20
## Residual Sum of Squares: 4.8454e+20
## R-Squared:      0.074684
## Adj. R-Squared: -0.029788
## F-statistic: 5.00411 on 1 and 62 DF, p-value: 0.028892</code></pre>
<p>Here you can check the individual intercepts through <code>fixef(fixed</code>). The coefficient of <span class="math inline">\(X_{1}\)</span> indicates how much <span class="math inline">\(Y\)</span> changes on average over time per country: as you can see the results are identical to the results we got from running the LSDV model. Arguably, however, running your model with explicit dummy variables is more informative.</p>
</div>
</div>
<div id="random-effects-models" class="section level3" number="2.3.4">
<h3><span class="header-section-number">2.3.4</span> Random effects models</h3>
<p>Random effects are the opposite of fixed effects. Contrary to fixed effects, random effects are random and difficult to predict. As such, the effect they will have on a dependent variable <span class="math inline">\(Y\)</span> is not constant. Think of the cost of renting a one bedroom appartement: <a href="https://www.ons.gov.uk/economy/inflationandpriceindices/bulletins/indexofprivatehousingrentalprices/may2020#:~:text=Private%20rental%20prices%20paid%20by,12%20months%20to%20May%202020.">rental prices vary greatly</a> depending on location.</p>
<p>If you have reason to believe that differences across entities have some influence on the dependent variable that is not time-dependent, then you would use a random effects model approach over a fixed effects model approach.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="statistical-inference-and-causality.html#cb20-1" aria-hidden="true"></a><span class="co"># run a random effects model</span></span>
<span id="cb20-2"><a href="statistical-inference-and-causality.html#cb20-2" aria-hidden="true"></a>random_effects &lt;-<span class="st"> </span><span class="kw">plm</span>(y <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data=</span>country_panel, <span class="dt">model=</span><span class="st">&#39;random&#39;</span>)</span>
<span id="cb20-3"><a href="statistical-inference-and-causality.html#cb20-3" aria-hidden="true"></a></span>
<span id="cb20-4"><a href="statistical-inference-and-causality.html#cb20-4" aria-hidden="true"></a><span class="co"># summary</span></span>
<span id="cb20-5"><a href="statistical-inference-and-causality.html#cb20-5" aria-hidden="true"></a><span class="kw">summary</span>(random_effects)</span></code></pre></div>
<pre><code>## Oneway (individual) effect Random Effect Model 
##    (Swamy-Arora&#39;s transformation)
## 
## Call:
## plm(formula = y ~ x1, data = country_panel, model = &quot;random&quot;)
## 
## Balanced Panel: n = 7, T = 10, N = 70
## 
## Effects:
##                     var   std.dev share
## idiosyncratic 7.815e+18 2.796e+09 0.873
## individual    1.133e+18 1.065e+09 0.127
## theta: 0.3611
## 
## Residuals:
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## -8.94e+09 -1.51e+09  2.82e+08  0.00e+00  1.56e+09  6.63e+09 
## 
## Coefficients:
##               Estimate Std. Error z-value Pr(&gt;|z|)
## (Intercept) 1037014329  790626206  1.3116   0.1896
## x1          1247001710  902145599  1.3823   0.1669
## 
## Total Sum of Squares:    5.6595e+20
## Residual Sum of Squares: 5.5048e+20
## R-Squared:      0.02733
## Adj. R-Squared: 0.013026
## Chisq: 1.91065 on 1 DF, p-value: 0.16689</code></pre>
<p>Interpretation of the coefficients is a little bit tricky since they include both the within-entity and between-entity effects. In this case, the data represents the average effect of <span class="math inline">\(X_{1}\)</span> over <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> changes across time and between countries by one unit.</p>
<p>If you are not sure whether you should run a fixed effects or a random effects model, you can run a Hausman test to help you with the decision. The Hausman test tests whether the variation across entities (i.e. countries in our example) is uncorrelated with the independent variables. The null hypothesis is that there is no such correlation: if the Hausman specification test comes back significant then it means that you should use a fixed effects model. You run it by comparing the results from both models!</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="statistical-inference-and-causality.html#cb22-1" aria-hidden="true"></a><span class="kw">phtest</span>(fixed_effects, random_effects)</span></code></pre></div>
<pre><code>## 
## 	Hausman Test
## 
## data:  y ~ x1
## chisq = 3.674, df = 1, p-value = 0.05527
## alternative hypothesis: one model is inconsistent</code></pre>
<p>According to the Hausman test, we should use the random effects model to estimate the relationship between <span class="math inline">\(x_1\)</span> and our <span class="math inline">\(Y\)</span>.</p>
<div class="note">
<p><strong>Note</strong><br/>
Normally, this is not the end of it as there is a sequence of tests that can and should be performed to make sure the model is valid. Testing for <a href="https://en.wikipedia.org/wiki/Heteroscedasticity">hetersokedaticity</a> and <a href="https://otexts.com/fpp2/stochastic-and-deterministic-trends.html">stochastic trends</a>, for instance. However, this is out of scope of the current module.</p>
</div>
</div>
</div>
<div id="thm-w02" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Take home message</h2>
<p>Different models are used for different research questions: the question guides the model. What is important to keep in mind, especially when working with machine learning models, is that not all models are suitable to say something about the relationships between variables. Let alone on whether variable <span class="math inline">\(X\)</span> is the cause of change in variable <span class="math inline">\(Y\)</span>. In this week’s material, we really wanted to introduce you to some models that do explicitly look at relationships between variables from an econometrics point of view - a very tiny sneak peak if you may. Of course, there are many other advanced econometric models such as models using <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation">instrumental variables</a> and <a href="https://en.wikipedia.org/wiki/Difference_in_differences">difference-in-differences</a> models. Inference is difficult but important in social science, and some of these traditional statistical/econometric method try to get more reliable estimates. What we will be learning in the next couple of weeks will be less interpretable/explanable but it is important to keep some of the issues that came to light during this week’s material in mind. That is it for this week!</p>
</div>
<div id="attributions_w02" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Attributions</h2>
<p>This week’s content and practical uses content and inspiration from:</p>
<ul>
<li>Torres-Reyna, Oscar. 2010. Getting Started in Fixed/Random Effects Models using R. <a href="https://rstudio-pubs-static.s3.amazonaws.com/372492_3e05f38dd3f248e89cdedd317d603b9a.html#45_regression_diagnostics">[Link]</a></li>
<li>Huntington-Klein, Nick. 2019. ECON 305: Economics, Causality, and Analytics. Lecture 13: Causality. <a href="http://www.nickchk.com/econ305.html">[Link]</a></li>
</ul>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-deep-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jtvandijk/GEOG0125/edit/master/02-week02.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["https://github.com/jtvandijk/GEOG0125/raw/master/02-week02.Rmd"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
